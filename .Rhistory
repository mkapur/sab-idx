head(gsub("."," ",(gsub(' ',"-",gsub("'","",Data_Set$Latitude)))))
head(paste(gsub(' ',"-",gsub("'","",Data_Set$Latitude)))))
head(paste(gsub(' ',"-",gsub("'","",Data_Set$Latitude))))
head(paste(gsub("'","",Data_Set$Latitude))))
head(paste(gsub("'","",Data_Set$Latitude)))
nospace
require(stringi)
head(strtrim(gsub("'","",Data_Set$Latitude)))
head(str_replace_all((gsub("'","",Data_Set$Latitude)), space(), ""))
require(stringr)
head(str_replace_all((gsub("'","",Data_Set$Latitude)), space(), ""))
??space
install.packages('stringr')
install.packages("stringr")
library(stringr)
head(str_replace_all((gsub("'","",Data_Set$Latitude)), space(), ""))
gsub(space(), "", gsub("'","",Data_Set$Latitude))
gsub(\s, "", gsub("'","",Data_Set$Latitude))
gsub("\s", "", gsub("'","",Data_Set$Latitude))
gsub("\\s", "", gsub("'","",Data_Set$Latitude))
head(gsub("\\s", "", gsub("'","",Data_Set$Latitude)))
head(gsub("\\s", ".", gsub(".","", gsub("'","",Data_Set$Latitude))))
head(gsub("\\s", ".", gsub("[.]","", gsub("'","",Data_Set$Latitude))))
Data_Set$Lat2 <- gsub("\\s", ".", gsub("[.]","", gsub("'","",Data_Set$Latitude)))
Data_Set$Lon2 <- gsub("\\s", ".", gsub("[.]","", gsub("'","",Data_Set$Longitude)))
Data_Set$Lon2 <- gsub("\\s", ".", gsub("[.]","", gsub("'","",Data_Set$Longitude)))
head(Data_Set)
with(Data_Set, plot(Lat2~Lon2))
hist(Data_Set$Longitude)
hist(Data_Set$Lon2)
Data_Set$Lon2[Data_Set$Lon2 > 0] <- Data_Set$Lon2[Data_Set$Lon2 > 0]*-1
## reformat lat-lon
Data_Set$Lat2 <- as.numeric(gsub("\\s", ".", gsub("[.]","", gsub("'","",Data_Set$Latitude))))
Data_Set$Lon2 <- as.numeric(gsub("\\s", ".", gsub("[.]","", gsub("'","",Data_Set$Longitude))))
Data_Set$Lon2[Data_Set$Lon2 > 0] <- Data_Set$Lon2[Data_Set$Lon2 > 0]*-1
### Input my data - *** DEMO: capelin data from AFSC Gulf of Alaska bottom trawl survey for 2001-2017 (odd years only), with in situ bottom temperatures ***
Data_Set <-  read.csv("./data/manual_compile_2019-05-13.csv", na.strings = "#N/A") %>% filter(!is.na(Latitude) & !is.na(Longitude))
### Input my data - *** DEMO: capelin data from AFSC Gulf of Alaska bottom trawl survey for 2001-2017 (odd years only), with in situ bottom temperatures ***
Data_Set <-  read.csv("./data/manual_compile_2019-05-13.csv", na.strings = "#N/A") %>% filter(!is.na(.$Latitude) & !is.na(.$Longitude))
## reformat lat-lon
Data_Set$Lat2 <- as.numeric(gsub("\\s", ".", gsub("[.]","", gsub("'","",Data_Set$Latitude))))
head(Data_Set)
head(Data_Set,25)
### Input my data - *** DEMO: capelin data from AFSC Gulf of Alaska bottom trawl survey for 2001-2017 (odd years only), with in situ bottom temperatures ***
Data_Set <-  read.csv("./data/manual_compile_2019-05-13.csv", na.strings = "#N/A")
sum(is.na(Data_Set$Latitude))
sum(is.na(Data_Set$Longitude))
head( as.numeric(gsub("\\s", ".", gsub("[.]","", gsub("'","",Data_Set$Latitude)))))
## reformat lat-lon
Data_Set$Lat2 <- as.numeric(gsub("\\s", ".", gsub("[.]","", gsub("'","",Data_Set$Latitude))))
Data_Set$Lon2 <- as.numeric(gsub("\\s", ".", gsub("[.]","", gsub("'","",Data_Set$Longitude))))
sum(is.na(Data_Set$Lon2))
subset(Data_Set,is.na(lon2))
subset(Data_Set,is.na(Lon2))
Data_Set[1401,'Longitude']
Data_Set[1401,'Longitude'] == ""
### Input my data - *** DEMO: capelin data from AFSC Gulf of Alaska bottom trawl survey for 2001-2017 (odd years only), with in situ bottom temperatures ***
Data_Set <-  read.csv("./data/manual_compile_2019-05-13.csv", na.strings = "#N/A") %>% filter(Longitude != "")
### Input my data - *** DEMO: capelin data from AFSC Gulf of Alaska bottom trawl survey for 2001-2017 (odd years only), with in situ bottom temperatures ***
Data_Set <-  read.csv("./data/manual_compile_2019-05-13.csv", na.strings = "#N/A") %>% filter(.$Longitude != "")
## reformat lat-lon
Data_Set$Lat2 <- as.numeric(gsub("\\s", ".", gsub("[.]","", gsub("'","",Data_Set$Latitude))))
Data_Set$Lon2 <- as.numeric(gsub("\\s", ".", gsub("[.]","", gsub("'","",Data_Set$Longitude))))
head(Data_Set)
Data_Set <- Data_Set[Longitude != "",]
Data_Set <- Data_Set[Data_Set$Longitude != "",]
### Input my data - *** DEMO: capelin data from AFSC Gulf of Alaska bottom trawl survey for 2001-2017 (odd years only), with in situ bottom temperatures ***
Data_Set <-  read.csv("./data/manual_compile_2019-05-13.csv", na.strings = "#N/A")
Data_Set <- Data_Set[Data_Set$Longitude != "",]
## reformat lat-lon
Data_Set$Lat2 <- as.numeric(gsub("\\s", ".", gsub("[.]","", gsub("'","",Data_Set$Latitude))))
Data_Set$Lon2 <- as.numeric(gsub("\\s", ".", gsub("[.]","", gsub("'","",Data_Set$Longitude))))
subset(Data_Set, is.na(Lon2))
### Input my data - *** DEMO: capelin data from AFSC Gulf of Alaska bottom trawl survey for 2001-2017 (odd years only), with in situ bottom temperatures ***
Data_Set <-  read.csv("./data/manual_compile_2019-05-13.csv", na.strings = "#N/A")
Data_Set <- Data_Set[Data_Set$Longitude != "",]
## reformat lat-lon
Data_Set$Lat2 <- as.numeric(gsub("\\s", ".", gsub("[.]","", gsub("'","",Data_Set$Latitude))))
Data_Set$Lon2 <- as.numeric(gsub("\\s", ".", gsub("[.]","", gsub("'","",Data_Set$Longitude))))
Data_Set$Lon2[Data_Set$Lon2 > 0] <- Data_Set$Lon2[Data_Set$Lon2 > 0]*-1
## Make a dummy column on Data_Set that can talk to the pre-set Extrapolation Grids
Data_Set$REG_BIG <- with(Data_Set, ifelse(Lat2 < 49, 'WC', 'AK'))
with(Data_Set, plot(Lat2 ~ Lon2))
Data_Set <-  read.csv("./data/manual_compile_2019-05-13.csv", na.strings = "#N/A")
Data_Set <- Data_Set[Data_Set$Longitude != "" & Data_Set$Latitude != ""  ,]
## reformat lat-lon
Data_Set$Lat2 <- as.numeric(gsub("\\s", ".", gsub("[.]","", gsub("'","",Data_Set$Latitude))))
Data_Set$Lon2 <- as.numeric(gsub("\\s", ".", gsub("[.]","", gsub("'","",Data_Set$Longitude))))
Data_Set$Lon2[Data_Set$Lon2 > 0] <- Data_Set$Lon2[Data_Set$Lon2 > 0]*-1
## Make a dummy column on Data_Set that can talk to the pre-set Extrapolation Grids
Data_Set$REG_BIG <- with(Data_Set, ifelse(Lat2 < 49, 'WC', 'AK'))
##### *** D. Extrapolation grid *** -- MAKE CUSTOM
# Region that tells software which grid to use
## thanks Jim
comblist <- list()
if('AK' %in% Data_Set$REG_BIG){
EBS_extrap = make_extrapolation_info(
Region = "Eastern_Bering_Sea",
strata.limits = strata.limits,
zone = 32,
flip_around_dateline = F
)
append(comblist, CC_extrap)
}
require(VAST)
if('AK' %in% Data_Set$REG_BIG){
EBS_extrap = make_extrapolation_info(
Region = "Eastern_Bering_Sea",
strata.limits = strata.limits,
zone = 32,
flip_around_dateline = F
)
append(comblist, CC_extrap)
}
CC_extrap = make_extrapolation_info(
Region = "california_current",
strata.limits = NA,
zone = 32,
flip_around_dateline = F
)
Data_Set <-  read.csv("./data/manual_compile_2019-05-13.csv", na.strings = "#N/A")
Data_Set <- Data_Set[Data_Set$Longitude != "" & Data_Set$Latitude != ""  ,]
## reformat lat-lon
Data_Set$LATITUDE <- as.numeric(gsub("\\s", ".", gsub("[.]","", gsub("'","",Data_Set$Latitude))))
Data_Set$LONGITUDE <- as.numeric(gsub("\\s", ".", gsub("[.]","", gsub("'","",Data_Set$Longitude))))
Data_Set$LONGITUDE[Data_Set$LONGITUDE > 0] <- Data_Set$LONGITUDE[Data_Set$LONGITUDE > 0]*-1
## Make a dummy column on Data_Set that can talk to the pre-set Extrapolation Grids
Data_Set$REG_BIG <- with(Data_Set, ifelse(LATITUDE < 49, 'WC', 'AK'))
# Extract strata boundaries by region - for
GOA.sl = c(range(Data_Set$LONGITUDE), range(Data_Set$LATITUDE))
WGOA.sl = c(range(Data_Set$LONGITUDE[Data_Set$fRegion=="WGOA"]), range(Data_Set$LATITUDE[Data_Set$fRegion=="WGOA"]))
CGOA.sl = c(range(Data_Set$LONGITUDE[Data_Set$fRegion=="CGOA"]), range(Data_Set$LATITUDE[Data_Set$fRegion=="CGOA"]))
grep("GOA",Data_Set$REG_AREA)
grep("GOA",Data_Set$Region)
##### *** D. Extrapolation grid *** -- MAKE CUSTOM
# Region that tells software which grid to use
## thanks Jim
comblist <- list(); strata.limits <- data.frame('STRATA'="All_areas")
EBS_extrap = make_extrapolation_info(
Region = "Eastern_Bering_Sea",
strata.limits = strata.limits,
zone = 32,
flip_around_dateline = F
)
append(comblist, CC_extrap)
if('AK' %in% Data_Set$REG_BIG){
# Extract strata boundaries by region - for
# GOA.sl = c(range(Data_Set$LONGITUDE), range(Data_Set$LATITUDE))
# WGOA.sl = c(range(Data_Set$LONGITUDE[Data_Set$fRegion=="WGOA"]), range(Data_Set$LATITUDE[Data_Set$fRegion=="WGOA"]))
# CGOA.sl = c(range(Data_Set$LONGITUDE[Data_Set$fRegion=="CGOA"]), range(Data_Set$LATITUDE[Data_Set$fRegion=="CGOA"]))
# NGOA.sl = c(range(Data_Set$LONGITUDE[Data_Set$fRegion=="NGOA"]), range(Data_Set$LATITUDE[Data_Set$fRegion=="NGOA"]))
# EGOA.sl = c(range(Data_Set$LONGITUDE[Data_Set$fRegion=="EGOA"]), range(Data_Set$LATITUDE[Data_Set$fRegion=="EGOA"]))
# Specify strata limits for GOA survey domain and 4 GOA subregions
# strata.limits <- data.frame(
#   'STRATA' = c("GOA","WGOA","CGOA","NGOA","EGOA"),
#   'west_border' = c(GOA.sl[1], WGOA.sl[1], CGOA.sl[1], NGOA.sl[1], EGOA.sl[1]),
#   'east_border' = c(GOA.sl[2], WGOA.sl[2], CGOA.sl[2], NGOA.sl[2], EGOA.sl[2]),
#   'north_border' = c(GOA.sl[4], WGOA.sl[4], CGOA.sl[4], NGOA.sl[4], EGOA.sl[4]),
#   'south_border' = c(GOA.sl[3], WGOA.sl[3], CGOA.sl[3], NGOA.sl[3], EGOA.sl[3]) )
EBS_extrap = make_extrapolation_info(
Region = "Eastern_Bering_Sea",
strata.limits = strata.limits,
zone = 32,
flip_around_dateline = F
)
append(comblist, CC_extrap)
}
##### *** D. Extrapolation grid *** -- MAKE CUSTOM
# Region that tells software which grid to use
## thanks Jim
comblist <- list(); strata.limits <- data.frame('STRATA'="All_areas")
if('AK' %in% Data_Set$REG_BIG){
# Extract strata boundaries by region - for
# GOA.sl = c(range(Data_Set$LONGITUDE), range(Data_Set$LATITUDE))
# WGOA.sl = c(range(Data_Set$LONGITUDE[Data_Set$fRegion=="WGOA"]), range(Data_Set$LATITUDE[Data_Set$fRegion=="WGOA"]))
# CGOA.sl = c(range(Data_Set$LONGITUDE[Data_Set$fRegion=="CGOA"]), range(Data_Set$LATITUDE[Data_Set$fRegion=="CGOA"]))
# NGOA.sl = c(range(Data_Set$LONGITUDE[Data_Set$fRegion=="NGOA"]), range(Data_Set$LATITUDE[Data_Set$fRegion=="NGOA"]))
# EGOA.sl = c(range(Data_Set$LONGITUDE[Data_Set$fRegion=="EGOA"]), range(Data_Set$LATITUDE[Data_Set$fRegion=="EGOA"]))
# Specify strata limits for GOA survey domain and 4 GOA subregions
# strata.limits <- data.frame(
#   'STRATA' = c("GOA","WGOA","CGOA","NGOA","EGOA"),
#   'west_border' = c(GOA.sl[1], WGOA.sl[1], CGOA.sl[1], NGOA.sl[1], EGOA.sl[1]),
#   'east_border' = c(GOA.sl[2], WGOA.sl[2], CGOA.sl[2], NGOA.sl[2], EGOA.sl[2]),
#   'north_border' = c(GOA.sl[4], WGOA.sl[4], CGOA.sl[4], NGOA.sl[4], EGOA.sl[4]),
#   'south_border' = c(GOA.sl[3], WGOA.sl[3], CGOA.sl[3], NGOA.sl[3], EGOA.sl[3]) )
EBS_extrap = make_extrapolation_info(
Region = "Eastern_Bering_Sea",
strata.limits = strata.limits,
zone = 32,
flip_around_dateline = F
)
append(comblist, EBS_extrap)
}
if('BC' %in% Data_Set$REG_BIG){
BC_extrap = make_extrapolation_info(
Region = "british_columbia",
strata.limits = NA,
zone = 32,
flip_around_dateline = F
)
BC_extrap$Data_Extrap$Area_km2 <- BC_extrap$Area_km2_x
names(BC_extrap$a_el) <- "All_areas"
append(comblist, CC_extrap)
}
if('WC' %in% Data_Set$REG_BIG){
CC_extrap = make_extrapolation_info(
Region = "california_current",
strata.limits = NA,
zone = 32,
flip_around_dateline = F
)
CC_extrap$Data_Extrap$Area_km2 <- CC_extrap$Area_km2_x
append(comblist, CC_extrap)
}
CC_extrap = make_extrapolation_info(
Region = "california_current",
strata.limits = strata.limits,
zone = 32,
flip_around_dateline = F
)
CC_extrap$Data_Extrap$Area_km2 <- CC_extrap$Area_km2_x
append(comblist, CC_extrap)
Extrapolation_List <- combine_extrapolation_info(
"AK" = AK_extrap,
"CC" = CC_extrap)
Extrapolation_List <- combine_extrapolation_info(
"AK" = EBS_extrap,
"CC" = CC_extrap)
?FishStatsUtils::make_extrapolation_info(
0
FishStatsUtils::make_extrapolation_info
?FishStatsUtils::make_extrapolation_info
Extrapolation_List = FishStatsUtils::make_extrapolation_info( Region=c('eastern_bering_sea','california_current'), strata.limits=strata.limits,
observations_LL = Data_Geostat[,c("Lat","Lon")] )
Extrapolation_List = FishStatsUtils::make_extrapolation_info( Region=c('eastern_bering_sea','california_current'),
strata.limits=strata.limits,
observations_LL = Data_Geostat[,c("LATITUDE","LONGITUDE")] )
Extrapolation_List <- combine_extrapolation_info(
"AK" = EBS_extrap,
"CC" = CC_extrap)
# Derived objects for spatio-temporal estimation
Spatial_List = SpatialDeltaGLMM::Spatial_Information_Fn( grid_size_km=grid_size_km, n_x=n_x, Method=Method,
Lon=Data_Geostat[,'Lon'], Lat=Data_Geostat[,'Lat'],
Extrapolation_List=Extrapolation_List, randomseed=Kmeans_Config[["randomseed"]],
nstart=Kmeans_Config[["nstart"]], iter.max=Kmeans_Config[["iter.max"]],
DirPath=DateFile, Save_Results=FALSE )
library(TMB)
library(VAST)
library(TMBhelper)
library(ThorsonUtilities)
install_github("nwfsc-assess/geostatistical_delta-GLMM", ref="3.3.0")
# Load package
library(SpatialDeltaGLMM)
require(devtools)
install_github("nwfsc-assess/geostatistical_delta-GLMM", ref="3.3.0")
library(SpatialDeltaGLMM)
install_github("nwfsc-assess/geostatistical_delta-GLMM", ref="3.3.0")
update.packages('colorspace')
library(SpatialDeltaGLMM)
install_github("nwfsc-assess/geostatistical_delta-GLMM", ref="3.3.0")
install.packages('colorspace')
install_github("nwfsc-assess/geostatistical_delta-GLMM", ref="3.3.0")
install.packages("colorspace")
install_github("nwfsc-assess/geostatistical_delta-GLMM", ref="3.3.0")
# Load package
require(devtools)
install_github("nwfsc-assess/geostatistical_delta-GLMM", ref="3.3.0")
install.packages("colorspace")
require(colorspace)
remove.packages(colorspace)
remove.packages("colorspace")
install.packages("colorspace")
# Derived objects for spatio-temporal estimation
Spatial_List = SpatialDeltaGLMM::Spatial_Information_Fn( grid_size_km=grid_size_km, n_x=n_x, Method=Method,
Lon=Data_Geostat[,'Lon'], Lat=Data_Geostat[,'Lat'],
Extrapolation_List=Extrapolation_List, randomseed=Kmeans_Config[["randomseed"]],
nstart=Kmeans_Config[["nstart"]], iter.max=Kmeans_Config[["iter.max"]],
DirPath=DateFile, Save_Results=FALSE )
install_github("nwfsc-assess/geostatistical_delta-GLMM", ref="3.3.0")
library(TMB)
library(VAST)
library(TMBhelper)
library(ThorsonUtilities)
library(FishStatsUtils)
############################################################################################################################################################
### Define Model structure
##########################
rm(list=ls())
### Input my data - *** DEMO: capelin data from AFSC Gulf of Alaska bottom trawl survey for 2001-2017 (odd years only), with in situ bottom temperatures ***
Data_Set <-  read.csv("./data/manual_compile_2019-05-13.csv", na.strings = "#N/A")
Data_Set <- Data_Set[Data_Set$Longitude != "" & Data_Set$Latitude != ""  ,]
## reformat lat-lon
Data_Set$LATITUDE <- as.numeric(gsub("\\s", ".", gsub("[.]","", gsub("'","",Data_Set$Latitude))))
Data_Set$LONGITUDE <- as.numeric(gsub("\\s", ".", gsub("[.]","", gsub("'","",Data_Set$Longitude))))
Data_Set$LONGITUDE[Data_Set$LONGITUDE > 0] <- Data_Set$LONGITUDE[Data_Set$LONGITUDE > 0]*-1
## Make a dummy column on Data_Set that can talk to the pre-set Extrapolation Grids
Data_Set$REG_BIG <- with(Data_Set, ifelse(LATITUDE < 49, 'WC', 'AK'))
# with(Data_Set, plot(Lat2 ~ Lon2))
Data_descrip = "IPHC_Survey_NPUE" #data description
### Define VAST version
#Version = get_latest_version(package = 'VAST') #demo is based on "VAST_v7_0_0"
Version = "VAST_v7_0_0"
##### *** A. Spatial settings: define the spatial resolution for the model, and whether to use a grid or mesh approximation ***
Method = c("Grid", "Mesh", "Spherical_mesh")[2]                        #mesh is default recommendation, number of knots need to be specified
grid_size_km = 25                                                      #Value only matters if Method="Grid"
n_x = 100                                                              #Number of "knots" used when Method="Mesh"
Kmeans_Config = list( "randomseed"=1, "nstart"=100, "iter.max"=1e3 )   #do not modify Kmeans set up
##### *** B. Model settings for each component of the model: ***
# FieldConfig: define if there is spatial (Omega) and spatio-temporal (Epsilon) variation
FieldConfig = c("Omega1"=1, "Epsilon1"=1, "Omega2"=1, "Epsilon2"=1)    #on, single factor
# RhoConfig: determine if there is autocorrelation across time for intecepts (Beta) and spatio-temporal variation (Epsilon)
RhoConfig = c("Beta1"=0, "Beta2"=0, "Epsilon1"=0, "Epsilon2"=0)        #off
# OverdispersionConfig: define if there overdispersion due to vessel effects
OverdispersionConfig = c("Delta1"=0, "Delta2"=0)                       #off
# bias.correct: implement epsilon bias correction estimator for nonlinear transformation of random effects
bias.correct = FALSE
# ObsModel: define distribution for errors and which model to run
ObsModel = c(2,0) #Conventional delta-model using clog-log link for encounter prob. & gamma distribution w/ log link for positive catches
##### *** C. Specified outputs calculated after model runs - what reports to create? ***
Options =  c("SD_site_density"=0, "SD_site_logdensity"=0, "Calculate_Range"=1, "Calculate_evenness"=0,
"Calculate_effective_area"=1, "Calculate_Cov_SE"=1, 'Calculate_Synchrony'=0, 'Calculate_Coherence'=0)
## Save files setting
# setwd(HomeDir)  #Make sure that the working directory is back where it started
# Create folder to store records
(DateFile <- paste0(getwd(),'/VAST_output_',Data_descrip,'_Dist=',ObsModel[1],'_Link=',ObsModel[2],'_',Version,'/')) #
dir.create(DateFile)
# Save all settings
Record = ThorsonUtilities::bundlelist( c("Data_Set","Version","Method","n_x","FieldConfig","RhoConfig","OverdispersionConfig","ObsModel","Kmeans_Config") )
save( Record, file=file.path(DateFile,"Record.RData"))
capture.output( Record, file=paste0(DateFile,"Record.txt"))
############################################################################################################################################################
### Preparing data for VAST
###########################
Data_Geostat = data.frame(Catch_KG = Data_Set$Sablefish_n3,
AreaSwept_km2 = rep(1,nrow(Data_Set)), #set to 1 since CPUEs already standardized
Year = Data_Set$YEAR,
Year_Num = as.factor(Data_Set$YEAR),
Lat = Data_Set$Latitude,
Lon = Data_Set$Longitude,
Station = Data_Set$Station,
Vessel = rep("IPHC", nrow(Data_Set)),
fRegion = Data_Set$REG_AREA,     #Categorical factor for GOA subregions
BtmDepth = Data_Set$Depth..F.,  #Continuous covariate
fBtmDepth = Data_Set$Depth..F., #Categorical factor for bottom depth
BtmTemp = rep(NA, nrow(Data_Set))     #Continuous covariate
)
levels(Data_Geostat$Year_Num) <- c(1:length(unique(Data_Set$YEAR)))
##### *** D. Extrapolation grid *** -- MAKE CUSTOM
# Region that tells software which grid to use
## thanks Jim
comblist <- list(); strata.limits <- data.frame('STRATA'="All_areas")
EBS_extrap = make_extrapolation_info( Region = "Eastern_Bering_Sea", strata.limits = strata.limits, zone = 32, flip_around_dateline = F )
NBS_extrap = make_extrapolation_info( Region = "Northern_Bering_Sea", strata.limits = strata.limits, zone = 32, flip_around_dateline = F )
GOA_extrap = make_extrapolation_info( Region = "gulf_of_alaska", strata.limits = strata.limits, zone = 32, flip_around_dateline = T )
# BC_extrap = make_extrapolation_info( Region = "british_columbia", strata.limits = strata.limits, zone = 32, flip_around_dateline = F )
# BC_extrap$Data_Extrap$Area_km2 <- BC_extrap$Area_km2_x
# names(BC_extrap$a_el) <- "All_areas"
CC_extrap = make_extrapolation_info( Region = "california_current", strata.limits = strata.limits, zone = 32, flip_around_dateline = TRUE )
CC_extrap$Data_Extrap$Area_km2 <- CC_extrap$Area_km2_x
Extrapolation_List = combine_extrapolation_info(
"EBS" = EBS_extrap,
"NBS" = NBS_extrap,
"GOA" = GOA_extrap,
# "BC" = BC_extrap,
"CC" = CC_extrap
)
# Derived objects for spatio-temporal estimation
Spatial_List = SpatialDeltaGLMM::Spatial_Information_Fn( grid_size_km=grid_size_km, n_x=n_x, Method=Method,
Lon=Data_Geostat[,'Lon'], Lat=Data_Geostat[,'Lat'],
Extrapolation_List=Extrapolation_List, randomseed=Kmeans_Config[["randomseed"]],
nstart=Kmeans_Config[["nstart"]], iter.max=Kmeans_Config[["iter.max"]],
DirPath=DateFile, Save_Results=FALSE )
install_github("nwfsc-assess/geostatistical_delta-GLMM", ref="3.3.0")
require(devtools)
install_github("nwfsc-assess/geostatistical_delta-GLMM", ref="3.3.0")
# Derived objects for spatio-temporal estimation
Spatial_List = SpatialDeltaGLMM::Spatial_Information_Fn( grid_size_km=grid_size_km, n_x=n_x, Method=Method,
Lon=Data_Geostat[,'Lon'], Lat=Data_Geostat[,'Lat'],
Extrapolation_List=Extrapolation_List, randomseed=Kmeans_Config[["randomseed"]],
nstart=Kmeans_Config[["nstart"]], iter.max=Kmeans_Config[["iter.max"]],
DirPath=DateFile, Save_Results=FALSE )
# Derived objects for spatio-temporal estimation
Spatial_List = SpatialDeltaGLMM:::Spatial_Information_Fn( grid_size_km=grid_size_km, n_x=n_x, Method=Method,
Lon=Data_Geostat[,'Lon'], Lat=Data_Geostat[,'Lat'],
Extrapolation_List=Extrapolation_List, randomseed=Kmeans_Config[["randomseed"]],
nstart=Kmeans_Config[["nstart"]], iter.max=Kmeans_Config[["iter.max"]],
DirPath=DateFile, Save_Results=FALSE )
# Derived objects for spatio-temporal estimation
Spatial_List = SpatialDeltaGLMM::Spatial_Information_Fn( grid_size_km=grid_size_km, n_x=n_x, Method=Method,
Lon=Data_Geostat[,'Lon'], Lat=Data_Geostat[,'Lat'],
Extrapolation_List=Extrapolation_List, randomseed=Kmeans_Config[["randomseed"]],
nstart=Kmeans_Config[["nstart"]], iter.max=Kmeans_Config[["iter.max"]],
DirPath=DateFile, Save_Results=FALSE )
Spatial_Information_Fn( grid_size_km=grid_size_km, n_x=n_x, Method=Method,
Lon=Data_Geostat[,'Lon'], Lat=Data_Geostat[,'Lat'],
Extrapolation_List=Extrapolation_List, randomseed=Kmeans_Config[["randomseed"]],
nstart=Kmeans_Config[["nstart"]], iter.max=Kmeans_Config[["iter.max"]],
DirPath=DateFile, Save_Results=FALSE )
############################################################################################################################################################
### Define Model structure
##########################
rm(list=ls())
library(TMB)
library(VAST)
library(TMBhelper)
library(ThorsonUtilities)
############################################################################################################################################################
### Define Model structure
##########################
rm(list=ls())
HomeDir <- getwd()
### Input my data - *** DEMO: capelin data from AFSC Gulf of Alaska bottom trawl survey for 2001-2017 (odd years only), with in situ bottom temperatures ***
Data_Set <- read.csv("vast-examples/GOA BT survey 2001-2017_capelin.csv", header=TRUE)
Data_descrip = "goaBT2001-2017_capelin" #data description
### Define VAST version
### Define VAST version
#Version = get_latest_version(package = 'VAST') #demo is based on "VAST_v7_0_0"
Version = "VAST_v7_0_0"
##### *** A. Spatial settings: define the spatial resolution for the model, and whether to use a grid or mesh approximation ***
Method = c("Grid", "Mesh", "Spherical_mesh")[2]                        #mesh is default recommendation, number of knots need to be specified
grid_size_km = 25                                                      #Value only matters if Method="Grid"
n_x = 100                                                              #Number of "knots" used when Method="Mesh"
Kmeans_Config = list( "randomseed"=1, "nstart"=100, "iter.max"=1e3 )   #do not modify Kmeans set up
##### *** B. Model settings for each component of the model: ***
# FieldConfig: define if there is spatial (Omega) and spatio-temporal (Epsilon) variation
FieldConfig = c("Omega1"=1, "Epsilon1"=1, "Omega2"=1, "Epsilon2"=1)    #on, single factor
# RhoConfig: determine if there is autocorrelation across time for intecepts (Beta) and spatio-temporal variation (Epsilon)
RhoConfig = c("Beta1"=0, "Beta2"=0, "Epsilon1"=0, "Epsilon2"=0)        #off
# OverdispersionConfig: define if there overdispersion due to vessel effects
OverdispersionConfig = c("Delta1"=0, "Delta2"=0)                       #off
# bias.correct: implement epsilon bias correction estimator for nonlinear transformation of random effects
bias.correct = FALSE
# ObsModel: define distribution for errors and which model to run
ObsModel = c(2,0) #Conventional delta-model using clog-log link for encounter prob. & gamma distribution w/ log link for positive catches
##### *** C. Specified outputs calculated after model runs - what reports to create? ***
Options =  c("SD_site_density"=0, "SD_site_logdensity"=0, "Calculate_Range"=1, "Calculate_evenness"=0,
"Calculate_effective_area"=1, "Calculate_Cov_SE"=1, 'Calculate_Synchrony'=0, 'Calculate_Coherence'=0)
### Save files setting
setwd(HomeDir)  #Make sure that the working directory is back where it started
# Create folder to store records
(DateFile <- paste0(getwd(),'/VAST_output_',Data_descrip,'_Dist=',ObsModel[1],'_Link=',ObsModel[2],'_',Version,'/')) #
dir.create(DateFile)
# Save all settings
Record = ThorsonUtilities::bundlelist( c("Data_Set","Version","Method","n_x","FieldConfig","RhoConfig","OverdispersionConfig","ObsModel","Kmeans_Config") )
save( Record, file=file.path(DateFile,"Record.RData"))
capture.output( Record, file=paste0(DateFile,"Record.txt"))
############################################################################################################################################################
### Preparing data for VAST
###########################
Data_Geostat = data.frame(Catch_KG = Data_Set$WTCPUE,
AreaSwept_km2 = rep(1,nrow(Data_Set)), #set to 1 since CPUEs already standardized
Year = Data_Set$YEAR,
Year_Num = as.factor(Data_Set$YEAR),
Lat = Data_Set$LATITUDE,
Lon = Data_Set$LONGITUDE,
Station = Data_Set$STATION,
Vessel = Data_Set$VESSEL,
fRegion = Data_Set$fRegion,     #Categorical factor for GOA subregions
BtmDepth = Data_Set$BOT_DEPTH,  #Continuous covariate
fBtmDepth = Data_Set$fBtmDepth, #Categorical factor for bottom depth
BtmTemp = Data_Set$BOT_TEMP     #Continuous covariate
)
levels(Data_Geostat$Year_Num) <- c(1:length(unique(Data_Set$YEAR)))
##### *** D. Extrapolation grid ***
# Region that tells software which grid to use
Region = "Gulf_of_Alaska"
# *** DEMO: how to include multiple strata within the extrapolation grid ***
# Extract strata boundaries by region - for
GOA.sl = c(range(Data_Set$LONGITUDE), range(Data_Set$LATITUDE))
WGOA.sl = c(range(Data_Set$LONGITUDE[Data_Set$fRegion=="WGOA"]), range(Data_Set$LATITUDE[Data_Set$fRegion=="WGOA"]))
CGOA.sl = c(range(Data_Set$LONGITUDE[Data_Set$fRegion=="CGOA"]), range(Data_Set$LATITUDE[Data_Set$fRegion=="CGOA"]))
NGOA.sl = c(range(Data_Set$LONGITUDE[Data_Set$fRegion=="NGOA"]), range(Data_Set$LATITUDE[Data_Set$fRegion=="NGOA"]))
EGOA.sl = c(range(Data_Set$LONGITUDE[Data_Set$fRegion=="EGOA"]), range(Data_Set$LATITUDE[Data_Set$fRegion=="EGOA"]))
# Specify strata limits for GOA survey domain and 4 GOA subregions
strata.limits <- data.frame(
'STRATA' = c("GOA","WGOA","CGOA","NGOA","EGOA"),
'west_border' = c(GOA.sl[1], WGOA.sl[1], CGOA.sl[1], NGOA.sl[1], EGOA.sl[1]),
'east_border' = c(GOA.sl[2], WGOA.sl[2], CGOA.sl[2], NGOA.sl[2], EGOA.sl[2]),
'north_border' = c(GOA.sl[4], WGOA.sl[4], CGOA.sl[4], NGOA.sl[4], EGOA.sl[4]),
'south_border' = c(GOA.sl[3], WGOA.sl[3], CGOA.sl[3], NGOA.sl[3], EGOA.sl[3]) )
Extrapolation_List = FishStatsUtils::make_extrapolation_info( Region=Region, strata.limits=strata.limits,
observations_LL = Data_Geostat[,c("Lat","Lon")] )
# Derived objects for spatio-temporal estimation
Spatial_List = SpatialDeltaGLMM::Spatial_Information_Fn( grid_size_km=grid_size_km, n_x=n_x, Method=Method,
Lon=Data_Geostat[,'Lon'], Lat=Data_Geostat[,'Lat'],
Extrapolation_List=Extrapolation_List, randomseed=Kmeans_Config[["randomseed"]],
nstart=Kmeans_Config[["nstart"]], iter.max=Kmeans_Config[["iter.max"]],
DirPath=DateFile, Save_Results=FALSE )
# Derived objects for spatio-temporal estimation
Spatial_List = SpatialDeltaGLMM:::Spatial_Information_Fn( grid_size_km=grid_size_km, n_x=n_x, Method=Method,
Lon=Data_Geostat[,'Lon'], Lat=Data_Geostat[,'Lat'],
Extrapolation_List=Extrapolation_List, randomseed=Kmeans_Config[["randomseed"]],
nstart=Kmeans_Config[["nstart"]], iter.max=Kmeans_Config[["iter.max"]],
DirPath=DateFile, Save_Results=FALSE )
# Derived objects for spatio-temporal estimation
Spatial_List = VAST::Spatial_Information_Fn( grid_size_km=grid_size_km, n_x=n_x, Method=Method,
Lon=Data_Geostat[,'Lon'], Lat=Data_Geostat[,'Lat'],
Extrapolation_List=Extrapolation_List, randomseed=Kmeans_Config[["randomseed"]],
nstart=Kmeans_Config[["nstart"]], iter.max=Kmeans_Config[["iter.max"]],
DirPath=DateFile, Save_Results=FALSE )
# Derived objects for spatio-temporal estimation
Spatial_List = SpatialDeltaGLMM::Spatial_Information_Fn( grid_size_km=grid_size_km, n_x=n_x, Method=Method,
Lon=Data_Geostat[,'Lon'], Lat=Data_Geostat[,'Lat'],
Extrapolation_List=Extrapolation_List, randomseed=Kmeans_Config[["randomseed"]],
nstart=Kmeans_Config[["nstart"]], iter.max=Kmeans_Config[["iter.max"]],
DirPath=DateFile, Save_Results=FALSE )
# Derived objects for spatio-temporal estimation
Spatial_List = SpatialDeltaGLMM::Spatial_Information_Fn( grid_size_km=grid_size_km, n_x=n_x, Method=Method,
Lon=Data_Geostat[,'Lon'], Lat=Data_Geostat[,'Lat'],
Extrapolation_List=Extrapolation_List, randomseed=Kmeans_Config[["randomseed"]],
nstart=Kmeans_Config[["nstart"]], iter.max=Kmeans_Config[["iter.max"]],
DirPath=DateFile, Save_Results=FALSE )
